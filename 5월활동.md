

👋 안녕하세요! 온니맛스의 제제입니다. 처음 인사드려요!



구관 어딘가에서 야근과 싸우던 MBTI I형 개발자들...
어느 날, 문득 이런 깨달음을 얻었습니다.

> 개발자 A: 나 이제 GPT 없으면 코드 못 짜… 진심이야…

그런데 이 와중에 데이터 분석가는 외칩니다.

> 분석가 B: 우리도 GPT 도움받고 싶은데… 데이터 표준은 있는데 왜 못 써?
> 아니…도메인마다 스키마 다르고 구조 다르고…이거 어떻게 적용해요오오오오?!

그리하여 저희는 결심했습니다.

> 💡 “AI가 처음부터 표준 데이터에 맞춰 추천해주면 되지 않을까?”
> 💡 “표준이 있을 때랑 없을 때, LLM 성능 차이도 검증해보자!”
> 💡 “계속 너희가 알아서 발전해라! (우리는 환경을 깔아주마!)”

이런 문제의식과 호기심에서, 이번 스터디는 시작되었습니다.

---

📌 **그래서 5월에는 뭘 했냐면요?**

1. **LLM 성능 평가 지표와 방법**을 조사하고,
2. 간단한 **PoC**도 만들어보고,
3. **데이터 허브와 표준 데이터 구조**도 살펴보고,
4. **text-to-SQL에 가장 적합한 모델**도 리서치했습니다!

---

### 📊 1. LLM 성능 평가 방법 리서치 & PoC 구현

GPT에게 표준 데이터를 줬을 때와 안 줬을 때,
**진짜 답변의 질이 달라질까?**

이를 검증하기 위해 다음을 시도했습니다:

* **정량적 평가:**

  * *ROUGE, BLEU, BERTScore* 등 텍스트 유사도 지표로 GPT 응답 비교
  * *응답 속도*와 *토큰 사용량*도 비교해 실제 서비스 효율성 평가

* **정성적 평가:**

  * 일관성, 명확성, 정확성 항목별로 사람이 직접 GPT 응답을 비교 평가
  * 반복 질문 시 GPT 응답의 안정성도 체크!

* 📌 *결론:*
  데이터 표준을 적용했을 때 **응답 품질이 전반적으로 향상**됨을 확인했습니다!
  (일관성 +1.3점, 명확성 +1.2점, 응답 속도 20% 개선)

---

### 🗂️ 2. DataHub & 표준 데이터 구조 탐색

"우리 조직에 데이터는 많은데, 표준은 왜 안 써요?"
→ 그건 데이터가 **어디서 왔고 어떻게 흘러가는지 모르기 때문!**

그래서 우리는 **LinkedIn의 DataHub**를 예제로 분석했고,
이런 흐름을 확인했습니다:

1. **리니지 추적:**
   데이터가 어디서 수집되고 어떻게 변형됐는지 확인!
2. **프로파일링:**
   컬럼 분포와 null 비율을 확인해 품질 진단!
3. **보안 정책 확인:**
   민감정보 여부와 접근 권한도 명확히!
4. **업무 도메인 중심 태깅 체계 설계:**
   '고객', '매출' 같은 주제 중심으로 자산 묶기!

📌 *결론:*
**데이터가 어떻게 살아있는지 보여주는 시각화**가 핵심!
→ 향후 실제 프로젝트에서도 도입해보고 싶다는 의견 다수!

---

### 💡 3. Text-to-SQL에 적합한 LLM 모델 리서치

"GPT가 SQL도 짜준다며? 근데 어떤 모델이 제일 잘해?"

그래서 저희는 모델을 다음 기준으로 비교했습니다:

* **한국어 응답 품질**
* **도메인 이해력 (NLU/NLG)**
* **보안성**
* **정형 데이터 기반 추론력**
* **멀티모달 처리 가능성**

🔎 분석한 모델 예시:

* 퍼블릭 LLM: GPT-4.5, Claude 3.5, Clova X
* 오픈소스: Llama 4, Gemma 3, Qwen 3, Mistral-Small 3.1

📌 *결론:*
한국어 도메인 응답이 필요한 환경에서는 아직 GPT 계열이 가장 안정적.
→ 다만, 오픈소스 모델도 빠르게 성장 중이라 **PoC에서의 활용 가능성 높음**

---

### 🤖 4. 표준 데이터 추천 알고리즘 설계 및 구현

"사용자 데이터 보고, 자동으로 표준 스키마 추천해줄 수 없을까?"

가능합니다! 그래서 이렇게 구현했습니다:

1. **OpenAI Embedding API로 텍스트 임베딩 생성**
2. **FAISS로 유사도 계산**
3. **가중 유사도 알고리즘으로 더 정확한 추천**
4. **향후 피드백 루프 및 강화학습 도입 계획**

📌 *결론:*
**“이 입력, 이런 표준 스키마가 어울려요!”**
→ 추천 정확도 높고, 도입 부담도 낮아서 바로 실무 PoC 가능!

---

## ✅ 마무리하며...

이 모든 리서치는 **“GPT를 어떻게 데이터 표준과 연결시킬까?”** 라는
실무적인 궁금증에서 시작되었습니다.

> "그냥 API 써봤다" 수준이 아닌,
> **정량적 지표 + 정성 평가 + 시스템 구현**까지 손으로 부딪혀본 한 달이었습니다!

다음 달에는 더 흥미로운 실험과 함께 돌아오겠습니다.
혹시 궁금한 점 있으시다면 언제든지 제제에게 말씀 주세요 🙋‍♀️

---

🧠 *GPT는 잘만 쓰면, 진짜로 실무도 바꿀 수 있어요.*
이 여정에 함께하고 싶으신 분, 환영합니다!

