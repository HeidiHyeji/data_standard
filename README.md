# 🧠 온니맛스 스터디 소개: GPT와 데이터 표준의 만남

## ✨ 스터디 목적

GPT가 코드를 도와주는 시대, 그렇다면 **데이터 분석가와 데이터 표준은 어떻게 공존할 수 있을까?**
우리는 다음과 같은 문제의식에서 시작했습니다.

> “도메인마다 다른 스키마, 다양한 용어, 흩어진 메타데이터 속에서
> GPT가 **정확하고 일관된 응답**을 하기 위해서는 무엇이 필요할까?”

바로 그 해답은 **데이터 표준**이었습니다.

---

## 📅 5월 활동 요약

### ✅ 1. LLM 성능 평가 실험 및 PoC 개발

* **표준 데이터 vs 비표준 데이터**로 질문할 때 GPT 응답의 질 차이를 측정
* **ROUGE, BLEU, BERTScore** 등 지표를 사용해 성능 평가 자동화
* Streamlit 기반의 **시각화 PoC** 구현

### ✅ 2. 데이터허브와 표준 데이터 구조 리서치

* LinkedIn의 [DataHub](https://datahubproject.io/) 분석
* 메타데이터 리니지(Lineage), 프로파일링, 도메인 태깅 구조 검토
* **실무 적용을 위한 설계 방향 탐색**

### ✅ 3. Text-to-SQL 모델 비교

* GPT, Claude, Clova 등 주요 LLM의 **NLU/NLG, 보안성, 한국어 대응력** 비교
* 도메인 기반 질의 대응력과 설명 능력 중심으로 검토

### ✅ 4. 표준 데이터 추천 알고리즘 설계

* OpenAI Embedding API + FAISS 기반의 **표준 스키마 추천 알고리즘 구현**
* 단순 유사도뿐 아니라 **가중치 기반 유사도** 및 향후 피드백 루프도 고려

---

## 🔧 이 저장소는?

스터디 PoC 및 리서치 자료들을 모아두는 저장소입니다!

* 사용자가 **표준 데이터를 DuckDB에 등록**
* 하나의 질문에 대해 **표준 기반 GPT vs 비표준 GPT**의 응답 비교
* ROUGE-L 점수를 통해 **성능 차이 자동 분석**

📂 이 레포지토리의 실제 코드들은 PoC 단계이므로, 오류와 버그 투성이입니다. 참고만 해주세요!

---

## 🙌 앞으로의 계획

* 정확한 데이터 표준을 도출하기 위한 파인튜닝 및 RAG 리서치
* 평가 지표 다각화 및 사용자 피드백 연동
* 연구를 통한 실제 업무 PoC 적용

함께 GPT 시대의 **데이터 표준 전략**을 고민하고 싶다면, 언제든지 환영합니다!


