{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ/LAsjaVYRkefDNzWsSCr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeidiHyeji/data_standard/blob/main/first_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai faiss-cpu numpy rouge_score -qqq"
      ],
      "metadata": {
        "id": "QJ4p-aVTDAUN",
        "outputId": "cbaddff5-7d8d-4b12-f755-e2fd5628814b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "sisKBhRcDDfD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x8egZmL3CS4g",
        "outputId": "9569e659-8d56-4223-9b36-be4097a8f1b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ÏÖã ROUGE Ï†êÏàò: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0, recall=0, fmeasure=0)}\n",
            "ÎπÑÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ÏÖã ROUGE Ï†êÏàò: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0, recall=0, fmeasure=0)}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# ChatGPT API Ìò∏Ï∂ú\n",
        "client = OpenAI(api_key=openai.api_key)\n",
        "\n",
        "def get_gpt_response(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ ÌëúÏ§Ä Ï†ÅÏö©Ìïú ÌîÑÎ°¨ÌîÑÌä∏\n",
        "standard_prompt = \"ÌëúÏ§ÄÌôîÎêú Îç∞Ïù¥ÌÑ∞: [ÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ ÏûÖÎ†• ÏòàÏãú], Ïù¥ Îç∞Ïù¥ÌÑ∞Î•º Í∏∞Î∞òÏúºÎ°ú XX Í≤∞Í≥ºÎ•º ÏòàÏ∏°Ìï¥Ï£ºÏÑ∏Ïöî.\"\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ ÌëúÏ§Ä ÎØ∏Ï†ÅÏö© ÌîÑÎ°¨ÌîÑÌä∏\n",
        "non_standard_prompt = \"ÎπÑÌëúÏ§ÄÌôîÎêú Îç∞Ïù¥ÌÑ∞: [ÎπÑÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ ÏûÖÎ†• ÏòàÏãú], Ïù¥ Îç∞Ïù¥ÌÑ∞Î•º Í∏∞Î∞òÏúºÎ°ú XX Í≤∞Í≥ºÎ•º ÏòàÏ∏°Ìï¥Ï£ºÏÑ∏Ïöî.\"\n",
        "\n",
        "standard_response = get_gpt_response(standard_prompt)\n",
        "non_standard_response = get_gpt_response(non_standard_prompt)\n",
        "\n",
        "# Ï∞∏Ï°∞ ÎãµÎ≥Ä\n",
        "reference_answer = \"Ï∞∏Ï°∞ Ï†ïÎãµ ÏòàÏãú\"\n",
        "\n",
        "# ROUGEÎ°ú ÌèâÍ∞Ä\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "standard_scores = scorer.score(reference_answer, standard_response)\n",
        "non_standard_scores = scorer.score(reference_answer, non_standard_response)\n",
        "\n",
        "print(f\"ÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ÏÖã ROUGE Ï†êÏàò: {standard_scores}\")\n",
        "print(f\"ÎπÑÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ÏÖã ROUGE Ï†êÏàò: {non_standard_scores}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# OpenAI API ÌÇ§ ÏÑ§Ï†ï\"\n",
        "\n",
        "# ÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÏòàÏãú\n",
        "standard_metadata = [\n",
        "    \"Í≥†Í∞ù_ÏïÑÏù¥Îîî (Customer ID, Ï†ïÏàòÌòï)\",\n",
        "    \"Íµ¨Îß§_ÎÇ†Ïßú (Purchase Date, YYYY-MM-DD)\",\n",
        "    \"ÏÉÅÌíà_ÏΩîÎìú (Product Code, Î¨∏ÏûêÏó¥)\"\n",
        "]\n",
        "\n",
        "# OpenAI ÏûÑÎ≤†Îî© Ìï®Ïàò Ï†ïÏùò\n",
        "def get_embedding(text):\n",
        "    response = openai.embeddings.create(\n",
        "        input=text,\n",
        "        model=\"text-embedding-ada-002\"\n",
        "    )\n",
        "    return np.array(response['data'][0]['embedding'])\n",
        "\n",
        "# ÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ ÏûÑÎ≤†Îî©\n",
        "standard_embeddings = np.array([get_embedding(text) for text in standard_metadata])\n",
        "\n",
        "# FAISS Ïù∏Îç±Ïä§ ÏÉùÏÑ± Î∞è Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä\n",
        "dimension = standard_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(standard_embeddings)\n",
        "\n",
        "# ÏÇ¨Ïö©Ïûê Îç∞Ïù¥ÌÑ∞ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÏòàÏãú (ÎπÑÌëúÏ§Ä)\n",
        "user_metadata = \"Í≥†Í∞ùÎ≤àÌò∏ (CustomerNumber, Ïà´ÏûêÌòï)\"\n",
        "\n",
        "# ÏÇ¨Ïö©Ïûê Îç∞Ïù¥ÌÑ∞ ÏûÑÎ≤†Îî©\n",
        "user_embedding = get_embedding(user_metadata).reshape(1, -1)\n",
        "\n",
        "# Ï∂îÏ≤ú ÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ Ï∞æÍ∏∞ (Í∞ÄÏû• Ïú†ÏÇ¨Ìïú Îç∞Ïù¥ÌÑ∞ 1Í∞ú Ï∂îÏ≤ú)\n",
        "distances, indices = index.search(user_embedding, k=1)\n",
        "recommended_standard = standard_metadata[indices[0][0]]\n",
        "\n",
        "print(\"üéØ Ï∂îÏ≤úÎêú ÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞:\", recommended_standard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "wBd6G1Fo0h5C",
        "outputId": "c8a9c4d0-6b8e-46ce-cb8b-8bd012161c65"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0bbfe4b34326>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# ÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ ÏûÑÎ≤†Îî©\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mstandard_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstandard_metadata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# FAISS Ïù∏Îç±Ïä§ ÏÉùÏÑ± Î∞è Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-0bbfe4b34326>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# ÌëúÏ§Ä Îç∞Ïù¥ÌÑ∞ ÏûÑÎ≤†Îî©\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mstandard_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstandard_metadata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# FAISS Ïù∏Îç±Ïä§ ÏÉùÏÑ± Î∞è Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-0bbfe4b34326>\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# OpenAI ÏûÑÎ≤†Îî© Ìï®Ïàò Ï†ïÏùò\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     response = openai.Embedding.get_embedding(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-ada-002\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y6ClQyj20nmk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
